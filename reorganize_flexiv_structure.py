#!/usr/bin/env python3
"""
é‡æ–°ç»„ç»‡Flexivæ•°æ®é›†ç»“æ„ï¼Œä½¿å…¶ä¸DROIDæ ‡å‡†ç»“æ„ä¸€è‡´

ä»ï¼š
flexiv_data/
â”œâ”€â”€ 0/latent_videos/0/
â”œâ”€â”€ 1/latent_videos/0/
â””â”€â”€ annotation/train/0.json

åˆ°ï¼š
flexiv_data/
â”œâ”€â”€ latent_videos/
â”‚   â”œâ”€â”€ train/0/0/  â† episode/camera
â”‚   â””â”€â”€ val/16/0/
â””â”€â”€ annotation/
    â”œâ”€â”€ train/0.json
    â””â”€â”€ val/16.json
"""

import os
import shutil
import json
from pathlib import Path
from tqdm import tqdm

def reorganize_flexiv_dataset(base_dir):
    """é‡æ–°ç»„ç»‡Flexivæ•°æ®é›†ç»“æ„"""
    base_path = Path(base_dir)
    
    # åˆ›å»ºæ–°çš„ç›®å½•ç»“æ„
    new_latent_dir = base_path / "latent_videos_new"
    new_latent_dir.mkdir(exist_ok=True)
    (new_latent_dir / "train").mkdir(exist_ok=True)
    (new_latent_dir / "val").mkdir(exist_ok=True)
    
    print("ğŸ”„ é‡æ–°ç»„ç»‡Flexivæ•°æ®é›†ç»“æ„...")
    print(f"   æºç›®å½•: {base_path}")
    
    # è¯»å–train_sample.jsonå’Œval_sample.jsonæ¥ç¡®å®šå“ªäº›æ˜¯è®­ç»ƒé›†ï¼Œå“ªäº›æ˜¯éªŒè¯é›†
    meta_info_path = Path("/root/workspace/chenyj36@xiaopeng.com/Ctrl-World/dataset_example/flexiv_data_meta_info/flexiv_1113")
    
    train_episodes = set()
    val_episodes = set()
    
    # è¯»å–è®­ç»ƒé›†episodes
    train_sample_file = meta_info_path / "train_sample.json"
    if train_sample_file.exists():
        with open(train_sample_file) as f:
            train_samples = json.load(f)
            for sample in train_samples:
                train_episodes.add(str(sample['episode_id']))
    
    # è¯»å–éªŒè¯é›†episodes
    val_sample_file = meta_info_path / "val_sample.json"
    if val_sample_file.exists():
        with open(val_sample_file) as f:
            val_samples = json.load(f)
            for sample in val_samples:
                val_episodes.add(str(sample['episode_id']))
    
    print(f"   è®­ç»ƒé›†episodes: {sorted(train_episodes)}")
    print(f"   éªŒè¯é›†episodes: {sorted(val_episodes)}")
    
    # éå†æ‰€æœ‰episodeç›®å½•
    episode_dirs = [d for d in base_path.iterdir() if d.is_dir() and d.name.isdigit()]
    
    moved_count = 0
    updated_annotations = {'train': [], 'val': []}
    
    for episode_dir in tqdm(sorted(episode_dirs, key=lambda x: int(x.name)), desc="ç§»åŠ¨latentæ–‡ä»¶"):
        episode_id = episode_dir.name
        
        # ç¡®å®šæ˜¯trainè¿˜æ˜¯val
        if episode_id in train_episodes:
            split = 'train'
        elif episode_id in val_episodes:
            split = 'val'
        else:
            print(f"âš ï¸  è­¦å‘Š: Episode {episode_id} ä¸åœ¨trainæˆ–valä¸­ï¼Œè·³è¿‡")
            continue
        
        # æ£€æŸ¥latent_videosç›®å½•
        old_latent_dir = episode_dir / "latent_videos"
        if not old_latent_dir.exists():
            print(f"âš ï¸  è­¦å‘Š: {old_latent_dir} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue
        
        # åˆ›å»ºæ–°çš„episodeç›®å½•
        new_episode_dir = new_latent_dir / split / episode_id
        new_episode_dir.mkdir(parents=True, exist_ok=True)
        
        # ç§»åŠ¨æ‰€æœ‰cameraç›®å½•
        for camera_dir in old_latent_dir.iterdir():
            if camera_dir.is_dir():
                camera_id = camera_dir.name
                new_camera_dir = new_episode_dir / camera_id
                
                # å¤åˆ¶ç›®å½•
                if new_camera_dir.exists():
                    shutil.rmtree(new_camera_dir)
                shutil.copytree(camera_dir, new_camera_dir)
                moved_count += 1
    
    print(f"\nâœ… ç§»åŠ¨äº† {moved_count} ä¸ªcameraç›®å½•")
    
    # æ›´æ–°annotationæ–‡ä»¶ä¸­çš„è·¯å¾„
    print("\nğŸ”„ æ›´æ–°annotationæ–‡ä»¶ä¸­çš„è·¯å¾„...")
    annotation_dir = base_path / "annotation"
    
    for split in ['train', 'val']:
        split_dir = annotation_dir / split
        if not split_dir.exists():
            continue
        
        for ann_file in split_dir.glob("*.json"):
            episode_id = ann_file.stem
            
            with open(ann_file, 'r') as f:
                data = json.load(f)
            
            # æ›´æ–°latent_videosè·¯å¾„
            if 'latent_videos' in data:
                for i, latent_info in enumerate(data['latent_videos']):
                    old_path = latent_info['latent_video_path']
                    # ä» "0/latent_videos/0/0.pt" æ”¹ä¸º "latent_videos/train/0/0/0.pt"
                    # è§£æè·¯å¾„
                    parts = old_path.split('/')
                    if len(parts) >= 4:
                        ep_id = parts[0]
                        camera_id = parts[2]
                        frame_file = parts[3]
                        new_path = f"latent_videos/{split}/{ep_id}/{camera_id}/{frame_file}"
                        data['latent_videos'][i]['latent_video_path'] = new_path
            
            # ä¿å­˜æ›´æ–°åçš„annotation
            with open(ann_file, 'w') as f:
                json.dump(data, f, indent=2)
            
            updated_annotations[split].append(episode_id)
    
    print(f"âœ… æ›´æ–°äº† {len(updated_annotations['train'])} ä¸ªè®­ç»ƒé›†annotation")
    print(f"âœ… æ›´æ–°äº† {len(updated_annotations['val'])} ä¸ªéªŒè¯é›†annotation")
    
    # é‡å‘½åç›®å½•
    print("\nğŸ”„ æ›¿æ¢æ—§çš„latent_videosç›®å½•...")
    old_latent_backup = base_path / "latent_videos_old_backup"
    old_latent = base_path / "latent_videos"
    
    # å¦‚æœå­˜åœ¨æ—§çš„latent_videosï¼Œå…ˆå¤‡ä»½
    if old_latent.exists():
        if old_latent_backup.exists():
            shutil.rmtree(old_latent_backup)
        shutil.move(str(old_latent), str(old_latent_backup))
        print(f"   æ—§latent_videoså·²å¤‡ä»½åˆ°: {old_latent_backup}")
    
    # é‡å‘½åæ–°ç›®å½•
    shutil.move(str(new_latent_dir), str(old_latent))
    print(f"âœ… æ–°ç»“æ„å·²ç”Ÿæ•ˆ: {old_latent}")
    
    # æ¸…ç†æ—§çš„episodeç›®å½•ï¼ˆä¿ç•™annotationå­ç›®å½•ï¼‰
    print("\nğŸ”„ æ¸…ç†æ—§çš„episodeç›®å½•...")
    cleaned = 0
    for episode_dir in episode_dirs:
        # åˆ é™¤latent_videoså­ç›®å½•
        latent_subdir = episode_dir / "latent_videos"
        if latent_subdir.exists():
            shutil.rmtree(latent_subdir)
        
        # åˆ é™¤annotationå­ç›®å½•ï¼ˆå·²ç»æœ‰ç»Ÿä¸€çš„annotationäº†ï¼‰
        ann_subdir = episode_dir / "annotation"
        if ann_subdir.exists():
            shutil.rmtree(ann_subdir)
        
        # å¦‚æœepisodeç›®å½•ä¸ºç©ºï¼Œåˆ é™¤å®ƒ
        if not any(episode_dir.iterdir()):
            episode_dir.rmdir()
            cleaned += 1
    
    print(f"âœ… æ¸…ç†äº† {cleaned} ä¸ªç©ºepisodeç›®å½•")
    
    # éªŒè¯æ–°ç»“æ„
    print("\n" + "="*50)
    print("ğŸ“Š éªŒè¯æ–°ç»“æ„:")
    print("="*50)
    
    train_latent_dir = old_latent / "train"
    val_latent_dir = old_latent / "val"
    
    train_episodes_count = len(list(train_latent_dir.iterdir())) if train_latent_dir.exists() else 0
    val_episodes_count = len(list(val_latent_dir.iterdir())) if val_latent_dir.exists() else 0
    
    print(f"âœ… latent_videos/train/: {train_episodes_count} episodes")
    print(f"âœ… latent_videos/val/: {val_episodes_count} episodes")
    print(f"âœ… annotation/train/: {len(updated_annotations['train'])} files")
    print(f"âœ… annotation/val/: {len(updated_annotations['val'])} files")
    
    # æ˜¾ç¤ºç¤ºä¾‹è·¯å¾„
    print("\nğŸ“ ç¤ºä¾‹è·¯å¾„:")
    if train_latent_dir.exists():
        example_files = list(train_latent_dir.glob("*/0/*.pt"))[:2]
        for f in example_files:
            rel_path = f.relative_to(base_path)
            print(f"   {rel_path}")
    
    print("\nğŸ‰ æ•°æ®é›†é‡ç»„å®Œæˆï¼")
    print(f"   âš ï¸  æ—§æ•°æ®å¤‡ä»½åœ¨: {old_latent_backup}")
    print(f"   å¦‚ç¡®è®¤æ— é—®é¢˜ï¼Œå¯æ‰‹åŠ¨åˆ é™¤: rm -rf {old_latent_backup}")

if __name__ == "__main__":
    base_dir = "/root/workspace/chenyj36@xiaopeng.com/Ctrl-World/dataset_example/flexiv_data"
    reorganize_flexiv_dataset(base_dir)

